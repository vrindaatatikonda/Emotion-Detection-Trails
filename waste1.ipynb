{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d500bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33846 images belonging to 6 classes.\n",
      "Found 7251 images belonging to 6 classes.\n",
      "Found 7259 images belonging to 6 classes.\n",
      "Classes: ['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m1,542\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,588,486</span> (9.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,588,486\u001b[0m (9.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">329,990</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m329,990\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,258,496</span> (8.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,258,496\u001b[0m (8.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Training top layers (base frozen)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dilip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982ms/step - accuracy: 0.3271 - loss: 1.8560\n",
      "Epoch 1: val_accuracy improved from None to 0.45359, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1180s\u001b[0m 1s/step - accuracy: 0.3630 - loss: 1.6565 - val_accuracy: 0.4536 - val_loss: 1.4185 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699ms/step - accuracy: 0.4071 - loss: 1.4867\n",
      "Epoch 2: val_accuracy improved from 0.45359 to 0.45483, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m875s\u001b[0m 827ms/step - accuracy: 0.4074 - loss: 1.4842 - val_accuracy: 0.4548 - val_loss: 1.3989 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717ms/step - accuracy: 0.4240 - loss: 1.4598\n",
      "Epoch 3: val_accuracy improved from 0.45483 to 0.46863, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m907s\u001b[0m 857ms/step - accuracy: 0.4206 - loss: 1.4615 - val_accuracy: 0.4686 - val_loss: 1.3801 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4274 - loss: 1.4427\n",
      "Epoch 4: val_accuracy improved from 0.46863 to 0.47221, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1497s\u001b[0m 1s/step - accuracy: 0.4258 - loss: 1.4481 - val_accuracy: 0.4722 - val_loss: 1.3687 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4348 - loss: 1.4400\n",
      "Epoch 5: val_accuracy did not improve from 0.47221\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1648s\u001b[0m 2s/step - accuracy: 0.4324 - loss: 1.4440 - val_accuracy: 0.3619 - val_loss: 2.2441 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4288 - loss: 1.4359\n",
      "Epoch 6: val_accuracy did not improve from 0.47221\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1654s\u001b[0m 2s/step - accuracy: 0.4288 - loss: 1.4409 - val_accuracy: 0.4215 - val_loss: 1.5462 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4259 - loss: 1.4418\n",
      "Epoch 7: val_accuracy improved from 0.47221 to 0.47428, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1892s\u001b[0m 2s/step - accuracy: 0.4312 - loss: 1.4354 - val_accuracy: 0.4743 - val_loss: 1.3662 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4368 - loss: 1.4271\n",
      "Epoch 8: val_accuracy did not improve from 0.47428\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1853s\u001b[0m 2s/step - accuracy: 0.4317 - loss: 1.4290 - val_accuracy: 0.4653 - val_loss: 1.3678 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4342 - loss: 1.4257\n",
      "Epoch 9: val_accuracy did not improve from 0.47428\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1743s\u001b[0m 2s/step - accuracy: 0.4362 - loss: 1.4241 - val_accuracy: 0.4696 - val_loss: 1.3682 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4498 - loss: 1.4084\n",
      "Epoch 10: val_accuracy did not improve from 0.47428\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1848s\u001b[0m 2s/step - accuracy: 0.4423 - loss: 1.4185 - val_accuracy: 0.4664 - val_loss: 1.3631 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4367 - loss: 1.4207\n",
      "Epoch 11: val_accuracy did not improve from 0.47428\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1662s\u001b[0m 2s/step - accuracy: 0.4391 - loss: 1.4202 - val_accuracy: 0.4710 - val_loss: 1.3598 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4425 - loss: 1.4159\n",
      "Epoch 12: val_accuracy improved from 0.47428 to 0.47938, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1656s\u001b[0m 2s/step - accuracy: 0.4427 - loss: 1.4190 - val_accuracy: 0.4794 - val_loss: 1.3548 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4447 - loss: 1.4109\n",
      "Epoch 13: val_accuracy improved from 0.47938 to 0.48573, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1676s\u001b[0m 2s/step - accuracy: 0.4439 - loss: 1.4137 - val_accuracy: 0.4857 - val_loss: 1.3424 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4397 - loss: 1.4155\n",
      "Epoch 14: val_accuracy did not improve from 0.48573\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1601s\u001b[0m 2s/step - accuracy: 0.4394 - loss: 1.4175 - val_accuracy: 0.4842 - val_loss: 1.3396 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4445 - loss: 1.4053\n",
      "Epoch 15: val_accuracy did not improve from 0.48573\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1637s\u001b[0m 2s/step - accuracy: 0.4439 - loss: 1.4110 - val_accuracy: 0.3514 - val_loss: 2.1389 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4422 - loss: 1.4145\n",
      "Epoch 16: val_accuracy did not improve from 0.48573\n",
      "\u001b[1m1058/1058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2297s\u001b[0m 2s/step - accuracy: 0.4454 - loss: 1.4085 - val_accuracy: 0.4775 - val_loss: 1.3491 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m 411/1058\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23:21\u001b[0m 2s/step - accuracy: 0.4497 - loss: 1.3980"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Transfer Learning with MobileNetV2 for Facial Emotion Recognition\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Dataset Paths\n",
    "# ------------------------------\n",
    "base_dir = r\"C:\\Users\\dilip\\OneDrive\\Documents\\Desktop\\EmoVision\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir   = os.path.join(base_dir, \"val\")\n",
    "test_dir  = os.path.join(base_dir, \"test\")\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Image Preprocessing & Augmentation\n",
    "# ------------------------------\n",
    "IMG_SIZE = (224, 224)   # MobileNetV2 expects 224x224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = len(train_gen.class_indices)\n",
    "class_labels = list(train_gen.class_indices.keys())\n",
    "print(\"Classes:\", class_labels)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Build MobileNetV2 Model\n",
    "# ------------------------------\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False  # Freeze base layers initially\n",
    "\n",
    "# Custom head for emotion classification\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Callbacks Setup\n",
    "# ------------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1)\n",
    "\n",
    "callbacks = [early_stop, lr_scheduler, checkpoint]\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Train the Model (Stage 1: Frozen Base)\n",
    "# ------------------------------\n",
    "print(\"\\n🔹 Training top layers (base frozen)...\")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=20,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Fine-Tune (Stage 2: Unfreeze last layers)\n",
    "# ------------------------------\n",
    "print(\"\\n🔹 Fine-tuning top layers of base model...\")\n",
    "\n",
    "# Unfreeze last 30 layers of MobileNetV2\n",
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers) - 30\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=3e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_gen,\n",
    "    epochs=50,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Combine Histories for Plot\n",
    "# ------------------------------\n",
    "acc = history.history['accuracy'] + history_fine.history['accuracy']\n",
    "val_acc = history.history['val_accuracy'] + history_fine.history['val_accuracy']\n",
    "loss = history.history['loss'] + history_fine.history['loss']\n",
    "val_loss = history.history['val_loss'] + history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# 8. Evaluate on Test Set\n",
    "# ------------------------------\n",
    "print(\"\\n🔹 Loading best saved model for evaluation...\")\n",
    "best_model = load_model(\"best_model.h5\")\n",
    "\n",
    "loss, acc = best_model.evaluate(test_gen)\n",
    "print(f\"\\n✅ Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# ------------------------------\n",
    "# 9. Confusion Matrix & Classification Report\n",
    "# ------------------------------\n",
    "y_true = test_gen.classes\n",
    "y_pred = np.argmax(best_model.predict(test_gen), axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\\n\",\n",
    "      classification_report(y_true, y_pred, target_names=class_labels, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
